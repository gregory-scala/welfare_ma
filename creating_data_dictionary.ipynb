{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a6ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###importing packages\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np; #importing packages we will use\n",
    "import matplotlib.pyplot as plt;\n",
    "import pandas as pd;\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from scipy.io import loadmat\n",
    "import os \n",
    "import scipy.linalg as la\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "import pickle\n",
    "import time\n",
    "from numba import jit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0488eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('G:\\\\Greg\\\\full_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ba4a8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing the plan data and the individual data from STATA\n",
    "\n",
    "os.chdir('G:\\\\Greg\\\\full_model')\n",
    "individual_data = pd.read_stata(r\"individual_data_2019.dta\")\n",
    "individual_data['income_h'] = individual_data['income_h']/100000\n",
    "individual_data['baseid'] = individual_data['baseid'].astype(str)\n",
    "individual_data.loc[individual_data['merge_variable'] == '', 'merge_variable'] = 'OO'\n",
    "plan_data_raw = pd.read_stata(r\"planinfo_data_2019.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "51f38a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "###droppping columns with missing data (except for annual drog deductible) (I pre-checked most of the data so I don't have\n",
    "# much missing data)\n",
    "\n",
    "cols_to_exclude = 'annualdrugdeductible'\n",
    "cols_to_check = [col for col in plan_data_raw.columns if col != cols_to_exclude]\n",
    "plan_data = plan_data_raw.dropna(subset=cols_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "df774a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##only keeping counties in both MCBS and plan-data\n",
    "\n",
    "individual_data_counties = individual_data['county_year'].unique()\n",
    "plan_data_counties = plan_data['county_year'].unique()\n",
    "usable_counties_1 = np.intersect1d(individual_data_counties,plan_data_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ea3939a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['state', 'county_landscape','monthlyconsolidatedpremiumi', 'annualdrugdeductible',\n",
    "               'year', 'year_str', 'merge_variable','plan_market_share','contract_plan_id','county_year', \n",
    "                'outside_option_share','firm_classification', 'name_merge','firmclassification_encoded','cpi_adjustment_factor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb74e8",
   "metadata": {},
   "source": [
    "### getting usable plans (dropping individuals with plans not-in usable_county_years or with plans not in plan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4c2bece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_data2 = plan_data[plan_data['county_year'].isin(usable_counties_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "96e0a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###getting all of the plans that are in the plan_level data (and appending the outside option)\n",
    "\n",
    "all_plans = plan_data2['merge_variable'].unique()\n",
    "len(all_plans)\n",
    "all_plans_OO = np.append(all_plans, 'OO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8480fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping plans that are in the usable county plans\n",
    "\n",
    "individual_data2 = individual_data[individual_data['county_year'].isin(usable_counties_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6eb01b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###drops around 1,000 people whose plan_ids aren't in the merged_data)\n",
    "\n",
    "individual_data_dropped = individual_data2[individual_data2['merge_variable'].isin(all_plans_OO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8deac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual_data_dropped is all of the individuals\n",
    "#plan_data2 is all of the data on plans that are not dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1f95e",
   "metadata": {},
   "source": [
    "### next, keep counties with at least three individuals, and two plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0324e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_by_county_year = individual_data_dropped.groupby('county_year').size().reset_index(name='individuals_county')\n",
    "individual_data_dropped = pd.merge(individual_data_dropped, observations_by_county_year, on='county_year')\n",
    "individual_data_3 = individual_data_dropped[individual_data_dropped['individuals_county']>= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf234ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_obs_cty_year = plan_data2.groupby('county_year').size().reset_index(name='plans_county')\n",
    "plan_data3 = pd.merge(plan_data2, plan_obs_cty_year, on='county_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5f5dd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##keep county_years of counties with at least two plans\n",
    "plan_data4 = plan_data3[plan_data3['plans_county']>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f16638a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###creating plans with usable county years\n",
    "\n",
    "usable_plan_counties = plan_data4['county_year'].unique()\n",
    "usable_individual_counties = individual_data_3['county_year'].unique()\n",
    "usable_county_years = np.intersect1d(usable_plan_counties,usable_individual_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2a4fb",
   "metadata": {},
   "source": [
    "### Doing some data modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9f241255",
   "metadata": {},
   "outputs": [],
   "source": [
    "###getting dummies for income terciles\n",
    "tercile_dummies = pd.get_dummies(individual_data_3['tercile_income'], prefix = 'income_tercile')\n",
    "health_dummies = pd.get_dummies(individual_data_3['genhelth'], prefix = 'healthcode')\n",
    "individual_data_4 = pd.concat([individual_data_3, tercile_dummies, health_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "535acd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##scaling variable\n",
    "\n",
    "individual_data_4.loc[individual_data_4['merge_variable'] == '', 'merge_variable'] = 'OO'\n",
    "individual_data_4['income_h'] = individual_data_4['income_h']/10000\n",
    "individual_data_4['income_h_sq'] = individual_data_4['income_h']**2\n",
    "individual_data_4['baseid'] = individual_data_4['baseid'].astype(str)\n",
    "individual_data_4['h_age'] = individual_data_4['h_age']/100\n",
    "individual_data_4['h_age_sq'] = individual_data_4['h_age']**2\n",
    "\n",
    "##modifying plan data \n",
    "plan_data4['eff_price'] = plan_data4['eff_price']/100\n",
    "plan_data4['costsharing_pmpm']= plan_data4['costsharing_pmpm']/100\n",
    "plan_data4['eff_premium_instrument1'] = plan_data4['eff_premium_instrument1']/100\n",
    "plan_data4['eff_premium_instrument2'] = plan_data4['eff_premium_instrument2']/100\n",
    "plan_data4['eff_premium_instrument_border'] = plan_data4['eff_premium_instrument_border']/100\n",
    "plan_data4['premium_instrument_1'] = plan_data4['premium_instrument_1']/100\n",
    "plan_data4['premium_instrument_2'] = plan_data4['premium_instrument_2']/100\n",
    "plan_data4['premium_instrument_border'] = plan_data4['premium_instrument_border']/100\n",
    "plan_data4['cs_instrument_1'] = plan_data4['cs_instrument_1']/100\n",
    "plan_data4['cs_instrument_2'] = plan_data4['cs_instrument_2']/100\n",
    "plan_data4['cs_instrument_border'] = plan_data4['cs_instrument_border']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "43c49c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###modifying the sample weights to weight each observation by it's proportion\n",
    "\n",
    "ever_enrolled_sum = individual_data_4['eeyrswgt'].sum()\n",
    "individual_data_4['eer_weight'] = individual_data_4['eeyrswgt'].apply(lambda x: x/ever_enrolled_sum)\n",
    "individual_data_4['weight_scaled'] = individual_data_4['eer_weight'].apply(lambda x: x*len(individual_data_4))\n",
    "individual_data_4['even_weight'] = 1/(len(individual_data_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d16f35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###adjusting for inflation\n",
    "monetary_variables = ['costsharing_pmpm', 'eff_premium_instrument1',\n",
    "       'eff_premium_instrument2', 'premium_instrument_1','premium_instrument_2', 'cs_instrument_1', 'cs_instrument_2',\n",
    "       'eff_premium_instrument_border', 'premium_instrument_border','cs_instrument_border', 'eff_price']\n",
    "\n",
    "plan_data4_adjusted = plan_data4[monetary_variables].div(plan_data4['cpi_adjustment_factor'], axis=0)\n",
    "plan_data4_adjusted.columns = [var + '_adjusted' for var in plan_data4_adjusted.columns]\n",
    "plan_data5 = pd.concat([plan_data4, plan_data4_adjusted], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70431b2",
   "metadata": {},
   "source": [
    "#### Getting dummy varibles for star_rating and drug rating status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6f67c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_dummies = pd.get_dummies(plan_data5['ssastatecountycode_string'], prefix='county')\n",
    "year_dummies = pd.get_dummies(plan_data5['year'], prefix='year')\n",
    "starrating_dummies = pd.get_dummies(plan_data5['star_string'], prefix='rating')\n",
    "drugbenefit_dummies = pd.get_dummies(plan_data5['drugbenefittype'], prefix = 'drugbenefit')\n",
    "\n",
    "plan_data5['firm_classification'] = plan_data5['firm_classification'].replace('Blue', 'Blue-Cross-Blue-Shield')\n",
    "##export plan_data5 to stata to get information\n",
    "\n",
    "plan_data5['lin_util_init'] = plan_data5['ln_sj_s0']\n",
    "plan_data5['mean_util_guess'] = plan_data5['ln_sj_s0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f531737",
   "metadata": {},
   "source": [
    "## Code to get data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "62e282eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###greating dictionary with the county_year as the key where I have, for each county\n",
    "# the individual_data from the MCBS and the plan_data from different plan_data files\n",
    "\n",
    "main_dictionary = {}\n",
    "\n",
    "for value in usable_county_years:\n",
    "    temp_data = individual_data_4[individual_data_4['county_year']==value]\n",
    "    temp_data2 = plan_data5[plan_data5['county_year']==value]\n",
    "    dict_temp = {value : {'individual_data': temp_data, 'plan_data': temp_data2}}\n",
    "    main_dictionary.update(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "811f4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "with open('main_dictionary_2019.pkl', 'wb') as fp:\n",
    "    pickle.dump(main_dictionary, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca23d18",
   "metadata": {},
   "source": [
    "#### saving useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f269d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "with open('useful_variables.pkl', 'wb') as fp:\n",
    "    pickle.dump(usable_county_years, fp)\n",
    "    print('variable saved successfully to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6456b64",
   "metadata": {},
   "source": [
    "### Getting individual and plan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fa84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('main_dictionary_2019.pkl', 'rb') as fp:\n",
    "    main_dictionary = pickle.load(fp)\n",
    "with open('useful_variables.pkl', 'rb') as fp:\n",
    "    usable_county_years = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f729cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GES58\\AppData\\Local\\Temp\\ipykernel_10044\\355933748.py:7: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    income_tercile_1.0   ->   income_tercile_1_0\n",
      "    income_tercile_2.0   ->   income_tercile_2_0\n",
      "    income_tercile_3.0   ->   income_tercile_3_0\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  individual_data_frame.to_stata('individual_data_usable_cty.dta')\n"
     ]
    }
   ],
   "source": [
    "##saving individual_data to use for summary statistics\n",
    "individual_data_frame = pd.DataFrame()\n",
    "\n",
    "for county in usable_county_years:\n",
    "    temp_df_ind = main_dictionary[county]['individual_data']\n",
    "    individual_data_frame = pd.concat([individual_data_frame, temp_df_ind])\n",
    "\n",
    "individual_data_frame.to_stata('individual_data_usable_cty.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5119d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GES58\\AppData\\Local\\Temp\\ipykernel_10044\\2213799824.py:7: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    eff_premium_instrument_border_adjusted   ->   eff_premium_instrument_border_ad\n",
      "    premium_instrument_border_adjusted   ->   premium_instrument_border_adjust\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  new_data_frame.to_stata('plan_data_usable_cty.dta')\n"
     ]
    }
   ],
   "source": [
    "#saving plan_data to use for summary_statistics\n",
    "new_data_frame = pd.DataFrame()\n",
    "\n",
    "for county in usable_county_years:\n",
    "    temp_df = main_dictionary[county]['plan_data']\n",
    "    new_data_frame =pd.concat([new_data_frame, temp_df])\n",
    "    \n",
    "new_data_frame.to_stata('plan_data_usable_cty.dta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
